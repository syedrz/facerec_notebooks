{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from clamv import *\n",
    "\n",
    "import os\n",
    "import cv2 \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load our dataset first \n",
    "y = []\n",
    "X = []\n",
    "for path in glob('../final_dataset/*/*'):\n",
    "    _, _, y1, name = path.split('/')\n",
    "    x1 = cv2.imread(path)\n",
    "    \n",
    "    y.append(y1)\n",
    "    X.append(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load lfw dataset\n",
    "output = fetch_lfw_people(color=True, min_faces_per_person=25, resize=1)\n",
    "lfw_X = output.images\n",
    "lfw_y = output.target\n",
    "\n",
    "lfw_names = output.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clmv_dict = {}\n",
    "for idx, val in enumerate(np.unique(y)):\n",
    "    clmv_dict[val] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = np.concatenate([np.unique(y), lfw_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx, n in enumerate(names):\n",
    "    names[idx] = n.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clmv_y = []\n",
    "for n in y:\n",
    "    clmv_y.append(clmv_dict[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_y = np.concatenate([clmv_y, lfw_y + len(np.unique(y))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Resize our X to right size\n",
    "resizer = Resizer(lfw_X.shape[2], lfw_X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clmv_resized_X = []\n",
    "for img in X:\n",
    "    clmv_resized_X.append(resizer(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clmv_resized_X = np.array(clmv_resized_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_X = np.concatenate([clmv_resized_X, lfw_X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('clmv_X.npy', final_X)\n",
    "np.save('clmv_y.npy', combined_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('clmv_names.npy', names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_yuv = []\n",
    "\n",
    "rgb2yuv = FormatConverter(source='RGB', dest='YUV', flip_axis=True)\n",
    "for x in final_X:\n",
    "    X_yuv.append(rgb2yuv(x))\n",
    "    \n",
    "X_yuv = np.array(X_yuv)\n",
    "X_yuv = X_yuv.reshape(len(X_yuv), 3, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X_yuv\n",
    "y = combined_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FisherFaces = Pipeline([\n",
    "    ('pca', MultiDimensionalModel(PCA(n_components=150), dimensions=3)),\n",
    "    ('lda', LDA()),\n",
    "    ('classify', SVC(kernel='linear', class_weight='balanced', probability=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create holdout\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pca', MultiDimensionalModel(dimensions=None,\n",
       "           models=[PCA(copy=True, iterated_power='auto', n_components=150, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False), PCA(copy=True, iterated_power='auto', n_components=150, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, wh...',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FisherFaces.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79117647058823526"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "out = FisherFaces.predict(X_test)\n",
    "accuracy_score(y_test, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "                     Brad       1.00      1.00      1.00         9\n",
      "                    Piotr       1.00      1.00      1.00         5\n",
      "                 Rhiannon       1.00      1.00      1.00         6\n",
      "                   Sophie       1.00      1.00      1.00         7\n",
      "                      Tom       1.00      1.00      1.00         5\n",
      "         Alejandro Toledo       0.58      0.78      0.67         9\n",
      "             Alvaro Uribe       0.67      0.57      0.62         7\n",
      "             Andre Agassi       1.00      0.58      0.74        12\n",
      "             Ariel Sharon       0.75      0.94      0.83        16\n",
      "    Arnold Schwarzenegger       0.33      0.38      0.35         8\n",
      "             Bill Clinton       0.75      0.43      0.55         7\n",
      "             Colin Powell       0.76      0.94      0.84        65\n",
      "            David Beckham       0.33      0.29      0.31         7\n",
      "          Donald Rumsfeld       0.75      0.86      0.80        35\n",
      "            George W Bush       0.81      0.93      0.87       132\n",
      "        Gerhard Schroeder       0.88      0.72      0.79        32\n",
      "  Gloria Macapagal Arroyo       0.80      1.00      0.89         4\n",
      "               Gray Davis       0.83      0.62      0.71         8\n",
      "          Guillermo Coria       0.60      0.75      0.67         4\n",
      "                Hans Blix       0.90      0.69      0.78        13\n",
      "              Hugo Chavez       0.79      0.90      0.84        21\n",
      "               Jack Straw       0.75      0.67      0.71         9\n",
      "           Jacques Chirac       0.70      0.64      0.67        11\n",
      "            Jean Chretien       0.82      0.64      0.72        22\n",
      "        Jennifer Capriati       0.90      0.64      0.75        14\n",
      "            John Ashcroft       0.80      0.86      0.83        14\n",
      "          John Negroponte       0.56      0.50      0.53        10\n",
      "      Juan Carlos Ferrero       0.80      0.57      0.67         7\n",
      "        Junichiro Koizumi       0.89      0.85      0.87        20\n",
      "               Kofi Annan       1.00      0.67      0.80         9\n",
      "               Laura Bush       0.92      1.00      0.96        11\n",
      "           Lleyton Hewitt       0.67      0.80      0.73         5\n",
      "Luiz Inacio Lula Da Silva       1.00      0.92      0.96        13\n",
      "            Mahmoud Abbas       0.86      0.86      0.86         7\n",
      "    Megawati Sukarnoputri       1.00      0.70      0.82        10\n",
      "          Nestor Kirchner       0.80      0.62      0.70        13\n",
      "     Recep Tayyip Erdogan       0.67      0.80      0.73         5\n",
      "            Ricardo Lagos       1.00      0.57      0.73         7\n",
      "             Roh Moo-Hyun       1.00      0.67      0.80         6\n",
      "         Rudolph Giuliani       0.25      0.25      0.25         4\n",
      "          Serena Williams       0.80      0.67      0.73        12\n",
      "        Silvio Berlusconi       0.25      0.17      0.20         6\n",
      "              Tom Daschle       1.00      0.50      0.67         2\n",
      "                Tom Ridge       1.00      0.88      0.93         8\n",
      "               Tony Blair       0.69      0.77      0.73        26\n",
      "              Vicente Fox       0.67      0.50      0.57         4\n",
      "           Vladimir Putin       0.73      0.62      0.67        13\n",
      "\n",
      "              avg / total       0.80      0.79      0.79       680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, out, target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Test On Haar Cascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this through the Haar Cascade classify each output then, output if the correct classification is made\n",
    "# Get each video from the dataset\n",
    "video_locations = []\n",
    "subjects = []\n",
    "for v in glob('../walk_videos/*'):\n",
    "    video_locations.append(v)\n",
    "    \n",
    "    video_name = v.split('/')[2]\n",
    "    subject = video_name.split('_')[0]\n",
    "    \n",
    "    subjects.append(subject.title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cascade = CascadeDetector('../recognition-pipeline/cascades/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gather from: ../walk_videos/alen_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tom/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gather from: ../walk_videos/alen_2.mp4\n",
      "Gather from: ../walk_videos/alen_3.mp4\n",
      "Gather from: ../walk_videos/brad_1.mp4\n",
      "Gather from: ../walk_videos/brad_2.mp4\n",
      "Gather from: ../walk_videos/piotr_1.mp4\n",
      "Gather from: ../walk_videos/rhiannon_1.mp4\n",
      "Gather from: ../walk_videos/sophie_1.mp4\n",
      "Gather from: ../walk_videos/sophie_2.mp4\n",
      "Gather from: ../walk_videos/tom_1.mp4\n",
      "Gather from: ../walk_videos/tom_2.mp4\n",
      "Gather from: ../walk_videos/walk_all.mp4\n"
     ]
    }
   ],
   "source": [
    "video_frames = []\n",
    "for path in video_locations:\n",
    "    frames = []\n",
    "    source = StaticSource(path, fps=25)\n",
    "    \n",
    "    print(\"Gather from: \" + path)\n",
    "    for f in source.__iter__():\n",
    "        if f[0] == None:\n",
    "            break\n",
    "        frames.append(f[0])\n",
    "        \n",
    "    video_frames.append(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subject_frames = []\n",
    "video_frames = np.array(video_frames)\n",
    "\n",
    "for video in video_frames:\n",
    "    faces = []\n",
    "    for frame in video:\n",
    "        for _, x, y, w, h in cascade._detect(frame):\n",
    "            faces.append(resizer(frame[y:y+h, x:x+w]))\n",
    "    \n",
    "    subject_frames.append(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decision = []\n",
    "for faces in subject_frames:\n",
    "    options = []\n",
    "    for idx, face in enumerate(faces):\n",
    "        new_face = rgb2yuv(face).reshape(1,3,-1)\n",
    "        \n",
    "        out = FisherFaces.predict_proba(new_face)\n",
    "        if np.max(out) >= THRESHOLD:\n",
    "            options.append((idx, names[np.argmax(out)]))\n",
    "            \n",
    "    decision.append(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [(38, 'Tom')],\n",
       " [(83, 'Brad'),\n",
       "  (100, 'Brad'),\n",
       "  (104, 'Brad'),\n",
       "  (106, 'Brad'),\n",
       "  (108, 'Brad'),\n",
       "  (110, 'Brad'),\n",
       "  (122, 'Brad')],\n",
       " [(23, 'Brad')],\n",
       " [],\n",
       " [(63, 'Vladimir Putin')],\n",
       " [],\n",
       " [],\n",
       " [(25, 'Tom'), (26, 'Tom'), (31, 'Tom')],\n",
       " [(41, 'Tom')],\n",
       " [(170, 'Tom'), (174, 'Tom'), (179, 'Tom'), (181, 'Tom')]]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
